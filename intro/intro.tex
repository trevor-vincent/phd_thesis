%REFERENCES used
%https://arxiv.org/pdf/1803.07965.pdf
%https://arxiv.org/pdf/1710.05832.pdf
%https://journals.aps.org/prd/pdf/10.1103/PhysRevD.95.024029 
%Appendix D in Rezolla hydrodynamics good for Tabulated Equation of State and geometrized units
%Constraints on the neutron star equation of state from AT2017gfo using radiative transfer simulations -> good for intro paragraph
% Evaluating radiation transport errors in merger simulations using a Monte-Carlo algorithm
% https://arxiv.org/abs/1805.11581 GW170817: Measurements of neutron star radii and equation of state
% wyatts paper
% https://www.fis.unipr.it/gravity/HomePages/Thesis/PhDthesis_2009_SebastianoBernuzzi.pdf
% https://arxiv.org/pdf/1804.06308.pdf

\chapter{Introduction}
\label{chap:intro}

The initial proposals for gravitational wave interferometers were
constructed in the late 1980s with the scientific goal to detect the inspiral and merger of compact-object binaries. Since then, the LIGO (\cite{ligo2018gwtc}), Virgo (\cite{acernese2015advanced}), and GEO600 (\cite{affeldt2014advanced}) detectors have been developed and operated as a network from 2005 to 2010. No detections were made during this initial stage of sensitivity. Alongside the early-2000 interferometer development, numerical simulations of the Einstein equations were beginning to gather ground. In 2000, the first binary neutron star merger was simulated (\cite{shibata2000simulation}), five years later the first binary black hole merger was computed after years of trial and error (\cite{pretorius2005a}) and finally in 2006 the first binary neutron star - black hole simulations were performed (\cite{shibata2006merger}). A variety of numerical relativity groups started forming at this time all around the globe, the Caltech-Cornell-CITA group (SXS; black-holes.org), the Kyoto/Tokyo group (\cite{nagakura:2014hza}), the University of Illinois at Urbana-Champaign group (UIUC), to name but a few. These groups started building simulation catalogs to aid in the parameter estimation studies that were expected to follow from the first detections. On September 9th, 2015, in a astonishing event during a engineering run, LIGO detected the gravitational wave from two coalescing black holes (\cite{theligoscientific:2016wfe}). Since this day, there have been multiple binary black hole waveform detections (\cite{ligo2018gwtc}). More recently however, LIGO made a landmark detection, GW170817 (\cite{abbott2017gw170817}). GW170817
coincided with the detection of a gamma ray burst, GRB 170817A and a series of observations that followed across the electromagnetic spectrum (e.g. \cite{villar:2017wcc}). The inferred masses of the bodies and the variety of electromagnetic observations imply that the source was a neutron star binary.

With these detections, and the awarding of the 2017 Nobel prize to three LIGO members, the gravitational era of astronomy was born. More detectors are expected in the future. With the upcoming earth-based detectors KAGRA (\cite{somiya2012detector}) and LIGO-India (gw-indigo.org), there will be a worldwide detector network capable of precise source localization. On top of this, there are already plans for third generation earth-based detectors such as the Einstein Telescope (\cite{einsteintelescope}) and space based detectors such as LISA (elisascience.org) which will cover an entirely different frequency band. With more and more detectors, both space-based and earth-based, we will be able to gather data from the full frequency spectrum of gravitational waves directed towards Earth.

The LIGO detection search and parameter estimator pipeline relies heavily on waveforms computed from numerical relativity. LIGO detects signals using a technique called matched-filtering, which compares instrument data against large catalogs of theoretically modelled waveform templates. These templates are created using a mix of post-Newtonian expansions, semi-analytic models tuned to numerical relativity and full numerical relativity waveforms (\cite{sachdev2019gstlal}). Furthermore, to extract the best astrophysical information from the instrument data, it is crucial to have numerical relativity waveforms. Parameter estimation in the first LIGO detection GW150914, of two coalescing black holes, used multiple semi-analytic models, tuned to numerical relativity waveforms, to determine source characteristics (\cite{abbott2016improved}). For the LIGO detection GW170817, there was both gravitational and electromagnetic emission. Post-Newtonian (PN) waveforms were used to estimate source parameters from the instrument data because in the frequency range detected the binary was well modelled by the PN expansion (\cite{abbott2017gw170817}). Even though the gravitational waveform did not capture details about the post-merger remnant, the electromagnetic emission from GW170817 provides information about this stage. Using the EM observations, fully relativistic simulations of binary neutron star mergers were used to help extract information about the remnant and constrain different aspects of the equation of state of nuclear matter. \cite{radice2017gw170817,shibata2017gw170817}. 

Even though numerical relativity has matured greatly since the major developments of the early 2000's, there is still a lot more that needs to be achieved. The biggest problems today in numerical relativity are the simulation of compact object binaries with matter and the simulation of supernovae, both requiring a great amount of microphysics, multi-scale grids, large sets of complex non-linear PDES, fast supercomputers and modern numerical techniques. With the coming of the exascale age of supercomputing there is an increasingly realistic chance of simulating these systems with all the known microphysics. This thesis aims to make progress in two areas of numerical relativity, both aiming at laying the groundwork for future BNS codes and analysis of LIGO BNS detections. First, we seek to improve the computational techniques used to solve the Einstein field equations so that more realistic microphysics may be introduced into the BNS simulations as computing power reaches exascale and beyond. To do this, we develop a new numerical scheme and code, which we test on several problems in numerical relativity, including a problem that mimicks the phase transitions discontinuities of a neutron star. This is outlined in Chapter 2. Secondly, we seek to further probe the parameter space of binary neutron star simulations with one of the most state of the art numerical relativity codes to help understand the emission properties of these LIGO sources for the next generation of detections. This is outlined in Chapter 3. Thus, this thesis is dedicated to the improving not only the current understanding of BNS mergers, but paving the way for more realistic future BNS merger simulations. The remaining portion of this introductory chapter will briefly describe the physics and computational techniques needed to understand the context of Chapters 2 and 3. We begin Chapter 1 with a high-level overview of BNS merger simulations and then in the following sections, we narrow down our focus to the numerical solving of the Einstein field equations for BNS simulations and the problems that current solvers have. We end Chapter 1 by introducing a new numerical method called discontinuous Galerkin which we plan on using to improve future BNS simulations.

%% With the BNS simulations we probe the parameter space with one of the best BNS/microphysics codes available and with our new code, we lay the groundwork for future investigations of BNS simulations which will involve even more complex microphysics.

\section{Binary Neutron Star (BNS) Simulations}


%% From Oertel EOS
%% The conditions in NS mergers are quite diverse. In
%% general they depend on the masses of the merging NSs
%% and the EoS and also on the magnetic fields and NS spins.
%% Typical temperatures in the core of a postmerger remnant
%% NS are in the range from 20 to 60 MeV (Bauswein, Janka,
%% and Oechslin, 2010). These temperatures can be well
%% exceeded in the contact layers in the early stage of the
%% merger, where extremely high temperatures up to 150 MeV
%% can occur locally (Bauswein, Janka, and Oechslin, 2010;
%% Rosswog, Piran, and Nakar, 2013). The highest densities in
%% the hot and rotating remnant NS are typically between 2nsat
%% and 6nsat (Hotokezaka, Kiuchi et al., 2013). In case the
%% remnant collapses to a BH, similar arguments as for failed
%% SNe apply: during the collapse much higher densities and
%% correspondingly higher temperatures are reached, but are
%% probably not important dynamically.
%% The dynamic ejecta of NS mergers originate from the crust
%% and outer core of the merging NSs. Initially, this material has
%% very low Y e in the range from 0.0 to 0.2 (Rosswog, Piran, and
%% Nakar, 2013; Sekiguchi et al., 2015). Depending on the
%% temperatures reached, the degeneracy of electrons is lifted
%% and Y e increases to higher values. In the subsequent evolution,
%% neutrino absorptions also influence Y e , resulting in final
%% values in the range of roughly 0.1 to 0.4 (Wanajo et al.,
%% 2014; Sekiguchi et al., 2015). See also Foucart et al. (2016)
%% for a comparison of the thermodynamic conditions for differ-
%% ent EoS. Figure 2 shows the thermodynamic conditions
%% reached in the remnant in the aftermath of a neutron star
%% merger. For the later ejecta that appear in the form of a
%% neutrino-driven wind, extremely high entropies per baryon

%% Shibata
%% As described in sections 1.4.8 and 1.5.1 (see, e.g., figure 1.23), binary neutron stars
%% are likely to be in quasi-circular orbits (with negligible eccentricity, e ≈ 0) in a late
%% inspiral phase. They adiabatically evolve due to the gravitational-radiation reaction
%% [see equation (1.93)] as far as the orbital radius, a, is much larger than the radius
%% of neutron stars, R. For the phase where a
%%  R, each neutron star in binaries
%% can be approximated by a point particle, and in addition, the orbital velocity is
%% at most 20 – 30% of the speed of light. The orbital evolution and emitted gravi-
%% tational waves in such inspiral phases are accurately and analytically determined
%% in post-Newtonian frameworks [Blanchet (2014)] combining the point-particle and
%% adiabatic approximations (see appendix H). However, for R/a >
%%  ∼ 0.2 (i.e., a <
%%  ∼ 50 –
%% 75 km for typical neutron-star radii, R = 10 – 15 km), neutron stars are deformed
%% by the tidal field of their companions, and hence, the point-particle approximation
%% becomes a poor approximation. Due to the tidal deformation of neutron stars,
%% the gravitational field and the orbital velocity are modified from the results by
%% the point-particle approximation. Therefore, finite-size effects have to be taken
%% into account. In addition, for a/6m ∼ <
%%  2.4 [see equation (1.93)], the ratio of the
%% Coalescence of binary compact objects
%%  449
%% gravitational-radiation reaction time scale to the orbital period is smaller than 10.
%% Here, for m = 2.8M, 6m ≈ 25 km. Thus, for a ∼ <
%%  60 km, the adiabatic approxima-
%% tion becomes a poor approximation (although it is qualitatively acceptable and does
%% not completely break down for a >
%%  ∼ 6m). For a ∼ <
%%  30 km, the gravitational-radiation
%% reaction time scale is as short as the orbital period, and hence, the system starts
%% dynamical evolution.
%% The brief summary described above shows that theoretical studies of binary neu-
%% tron stars should be done keeping the following facts in mind: (i) for a <
%%  ∼ 5R(= 50 –
%% 75 km), finite-size effects have to be incorporated; (ii) for 30 km <
%%  ∼ a <
%%  ∼ 60 km, non-
%% adiabatic effects for the inspiral orbits should be incorporated, (iii) for a ∼ <
%%  30 km,
%% the merger occurs and hence a fully dynamical treatment is the unique approach
%% for this stage. The finite-size effects can be incorporated only by fully solving
%% gravitational-field equations together with hydrodynamics equations. Hence, for
%% a<
%%  ∼ 5R, a numerical computation is necessary. However, this does not always imply
%% that numerical-relativity simulations are necessary for this phase. For a relatively
%% large orbital separation, e.g., a ∼ 50 km, the adiabatic approximation may still work,
%% because the gravitational-radiation reaction time scale is still ∼ 5 times as long as
%% the orbital period. For this phase, we may approximate the binary system in a sta-
%% tionary state when observing it in a frame comoving with the orbital velocity. Thus,
%% not only numerical-relativity simulations but also constructing quasi-equilibrium
%% sequences is one of the possible approaches for studying this evolution phase. Com-
%% puting quasi-equilibrium states is also the necessary element for the studies of binary
%% mergers, because they are used as initial data of numerical-relativity simulations.


%% Use Shibata, Faber and Metzger to put this section together
%% Make outline and where to use each
%% Make diagram like shibata

In the last section we outlined the grand scheme of this thesis and the chapters to follow. Now, we will start delving deeper into the binary neutron stars. In this section, we give a high-level overview of binary neutron star systems, and the computational work that has been performed to model them. 

%add disk masses and ejecta masses maybe

Binary neutron star systems typically arise from a high-mass binary star system (each having mass of about $\sim8-10M_\odot$), when each of the stars undergo a supernova explosion. If either of the supernovae do not unbind the two stars, then a binary neutron star system is born. As each neutron star in this binary orbits around each other, gravitional radiation is given off which reduces the separation $a$ of the neutron stars. If the neutron stars have a radius $R$, then when $a >> R$, the binaries slowly orbit each other with decreasing radius in a stage known as the \textbf{inspiral}. In this stage, the stars are well approximated as point particles and orbiting each other with speeds not exceeding $\sim 0.2c$. As the neutron stars approach and $a \sim 5R$, they become tidally deformed. The amount of deformation is governed by the equation of state (EOS) of the nuclear matter. As $a \sim 30km$ the stars plunge toward each other and merge into a single ot hypermassive neutron star, ejecting a large amount of material in the process. This ejecta fuses together new nuclei through the r-process and releases optical radiation upon the nuclei radioactively decaying. This stage is known as the \textbf{merger}. Whether this newly formed massive neutron star collapses down to a black-hole depends on the total mass of the system and the EOS. For most EOS, a binary of total mass close to $3M_\odot$ will collapse within a few ms after merger (see Chapter 3 for more details). Once the remant has settled into either a black-hole or a massive neutron star, we have reached the \textbf{ringdown} stage. The dynamics and observational signatures of the ringdown stage are dominated by the left-over accretion disk, which drives magnetic, viscous and neutrino winds and as GW170817 confirmed, is also the central engine for short gamma ray bursts (sGRB).

%add timescales here
Each stage of the binary coalescence is marked by differences in the gravitational wave. The early inspiral is marked by a sinusoidal pattern as the neutron stars slowly orbit each other like point particles. As the binary first enters the LIGO band in the late inspiral, the stars become tidally deformed. This tidal deformation induces a quadripole moment which changes the shape of waveform. The magnitude of the tidal deformation is governed by the EOS, so measurement of the tidal deformability can put constraints on the EOS, which was done for GW170817. As the stars plunge toward each other, the frequency grows rapidly and reaches its peak at merger, this rapid growth of the frequency is often called the ``chirp'' because it resembles a chirp sound if the frequencies were converted to sound waves. As the cores-bounce together during merger and rotate, the proto-remnant emits waves with a multiltude of frequencies with most of the emission in three major peak frequencies (the largest being from the rotation of the proto-remnant and the other two from the fundamental frequencies of a bouncing spring). These peaks are EOS dependent and thus can lead to constraints on the EOS, but unfortunately these peaks were outside of the LIGO band for GW170817. Lastly as the remnant settles, there is a decay of the frequency as energy is lost from the remnant. 

Until GW170817 there were two big mysteries surrounding BNS. The first mystery involved the so-called r-process elements. It was unclear for decades how approximately half of the elements in the Galaxy heavier than iron were formed. The formation of these elements required environments where the density of free neutrons would be so high that neutron captures on nuclei proceed much faster than β−decays. Such elements were called r-process elements. In 1974, Lattimer and Schramm proposed that these r-process elements could be formed in the neutron-rich matter ejected from neutron star - black-hole mergers. In 1989  Eichler et al. (1989) proposed that a similar mechanism of mass ejection could occur from merging compact binaries consisting of two NSs. It was shown in the decade following that newtonian neutron star simulations could produce ejecta from tidal disruption with the desired neutron-richness, speed and mass to potentially produce such elements. In the years that followed fully-general relativistic simulations were performed and showed that there was another 

For a long time it was unclear how approximately half of the elements in the Galaxy heavier than iron, Lattimer & Schramm (1974) proposed that the coalescence of a binary system consisting of a NS and
a stellar mass black hole (BH) would provide a promising source of neutron-rich ejecta conducive to the
r-process with a very low electron fraction Ye = np/(nn+np), where np and nn are the densities of protons
and neutrons, respectively. Following the ejection of NS matter through the outer binary Lagrange points
by tidal forces, its rapid decompression from nuclear densities would naturally result in the formation of
heavy nuclei through neutron capture (Lattimer et al., 1977; Meyer, 1989). Symbalisty & Schramm (1982)
and Eichler et al. (1989) proposed that a similar mechanism of mass ejection could occur from merging
compact binaries consisting of two NSs. The ejecta from the mergers. Roughly 60 years ago, Burbidge et al. (1957) and Cameron (1957) recognized that approximately half of the elements in the Galaxy heavier than iron must have been produced in an environment in which
2


Using updated models including the GW170817 observation, LIGO expects a detection rate of $110-3840 Gpc^-3 y^-1$ \cite{ligo2018gwtc} and with a Hanford detector radius of $\sim 107 Mpc$ (Livingston has $\sim 218 Mpc$ radius \cite{abbott2017gw170817} this means a minimum of $\sim 10$ BNS mergers could be detected by LIGO per year.






Neutron stars are amongst the most compact and extreme objects known in the universe and are believed to be born from the result of
massive stars going supernova. With core densities exceeding far beyond that
of the nucleus, conditions unreachable on earth, neutron stars provide an exceptional testing ground for nuclear physics. In particular, the merger of two neutron stars provides us with an unique opportunity to study the high density region of the equation of state (EOS), an equation describing the internal properties of the star. Furthermore, as confirmed by GW170817, NS mergers are progenitors for short Gamma ray bursts (sGRBs) and the
heavy neutron-rich elements in the universe, whose synthesis in the fast moving neutron-star ejecta produces the optical and near-infrared EM counterparts that accompany the gravitational wave signal. 

We can probe the EOS via the waveform in two main ways. First, as the stars come into close contact they start  


It is expected that with the increasing sensitivity of gravitational wave
interferometers multiple detections of merging BNSs will be made in the next years (\cite{ligo2018gwtc}). Therefore it will be crucial
to study the properties of these fascinating systems in order to extract information
from the data. While an analytical approach in general relativity is possible for the stage in which the two
bodies are distant, numerical computation of the field equations is required
for the last few orbits of the inspiral, the merger and the post-merger remnant stages. Thus it is imperative to have fully generalitivistic simulations of BNS mergers and NSBH mergers in order to maximize the science potential of the next era of detections.

The first general-relativistic simulation of BNS mergers were performed in 2000(\cite{shibata2000simulation}). However, despite continuous developments, current codes have not yet reached the accuracy required to model the gravitational wave signal and the electronmagnetic counterparts at the level required to extract as much information as possible from future detections (See (\cite{baiotti2016binary}). High accuracy is required because small numerical errors in the initial data solves or the evolution lead to larger errors in the waveform (See e.g. \cite{tsokaros2016initialfixed}). However, high-accuracy is very difficult to obtain currently because of the multi-scale nature of the problem, we have to have high enough resolution to resolve the Neutron star, but a large enough grid to extract the waveforms far away from the remnant. On top of this, most codes do not take into account all of the microphysics relevant to the evolution of the post-merger remnant, including a hot nuclear-theory based equation of state, a neutrino transport scheme accounting for both neutrino-matter and neutrino-neutrino interactions, and the evolution of the magnetic fields with enough resolution to resolve the growth of magneto-hydrodynamics instabilities (\cite{foucart2015low}). That being said, slowly but surely, different levels of micro-physics are being added to the codes. The first papers that studied fully general relativistic BNS simulations including the effects of neutrinos
were (\cite{neilsen2014magnetized, palenzuela2015effects}) with a simple leakage scheme and (\cite{sekiguchi2015dynamical}) with a more complex M1 neutrino transport scheme. Both the leakage scheme and M1 transport scheme are approximate methods to deal with neutrinos which are preferred because solving the 7-dimensional Boltzmann transport equation for the neutrino distribution during a BNS simulation is currently numerically intractable. For a review of leakage and the M1 transport scheme see (\cite{foucart2015post}). These BNS simulations with neutrino cooling and neutrino transport have focused mainly on equal mass systems with $M_{ns} = 1.35M_{\odot}$. Collectively these papers find that the ejected mass is only substantial  enough to explain the total mass of r-process heavy elements in our galaxy for r-process nucleo-synthesis in the case of a softer equation of state (e.g., more compact stars). The first paper on BNS mergers with neutrino interactions using the SpEC code looked at $1.2M_{\odot}$ equal mass systems and compared a simple leakage cooling neutrino scheme with the more complicated gray M1 neutrino transport scheme, finding that the more realistic transport scheme had a significant affect on the disk composition and the outflows, producing more neutron rich material that could possibly seed r-process element creation. (\cite{radice2016dynamical}) examined the effects of eccentricity and neutrino cooling on the matter outflows and remnant disk of a LS220 equal mass binary, finding that both had significant effects, with the absence of a neutrino scheme leading to matter outflows a factor of 2 off. Finally, only very recently have there been studies examining the effects on matter outflows due to mass asymmetry in the initial binaries, with both (\cite{lehner2016unequal}) and (\cite{sekiguchi2016dynamical}) finding that mass asymmetry can affect the neutron-richness and total ejecta for both soft and stiff equations of state.

In Chapter 3 of this thesis, we will be contributing to the above growing set of BNS studies, by looking at the effect of mass asymmetry and the EOS on matter and neutrino emissions using the SpEC code which now has a state-of-the-art neutrino transport scheme.



\section{Solving the Einstein Field Equations for BNS simulations}

In their usual form, space and time are treated on an equal footing in the Einstein equations. From the perspective of performing a numerical evolution however, we need to reformulate the problem as an initial value problem where we have a set of initial gravitational and matter data at some time $t$, and a set of evolution equations which we can use to get the updated data at a later time. To do this, we make the ansatz that space-time can be treated as a time sequence of spatial hypersurfaces. With this ansatz, the space-time metric $g_{\mu\nu}$ can be decomposed into

\begin{equation}
\label{eq:4}
ds^{2} = g_{\mu\nu}dx^{\mu}dx^{\nu} = -\alpha^2dt^2 + \gamma_{ij}(dx^i+\beta^idt)(dx^j+\beta^jdt),
\end{equation}
%
where the spatial metric $\gamma_{ij}$ is a function of the spatial coordinates $x^{i}$ and $t$, $\alpha$ is the lapse function that measures proper time between neighboring hypersurfaces along their timelike unit normals $n^{\mu}$ and $\beta^i$ is called the shift, which determines how coordinate labels move between each hypersurface. This is known as the 3+1 decomposition of the metric (\cite{arnowitt1959dynamical}).

Now we need to decompose the Einstein field equations into a set of evolution and constraint equations involving the quantities $\beta^i$, $\alpha$ and $\gamma_{ij}$. To do this, we introduce the projection operator $\perp^{\alpha}_{\beta} = \delta^{\alpha}_{\beta} + n^{\alpha} n_{\beta}$, which can be easily proven to project the space-time components orthogonal to $n^{\mu}$ out of any space-time vector.

The three possible projections of the Einstein field equations: $n^{\mu} n^{\nu} G_{\mu\nu} = 8\pi n^{\mu} n^{\nu} T_{\mu\nu}$, $n^{\mu}\perp^{\nu}_{\delta}G_{\mu\nu} = 8\pi n^{\mu} \perp^{\nu}_{\delta} T_{\mu\nu}$, $\perp^{\mu}_{\rho} \perp^{\nu}_{\delta} G_{\mu\nu} = 8\pi \perp^{\mu}_{\rho} \perp^{\nu}_{\delta} T_{\mu\nu}$ lead to the three York/ADM 3+1 equations respectively:
%
%% \begin{subequation}
\begin{align}
0 &= R + K^{2} - K^{mn}K_{mn} -16\pi\rho,\label{eq:3p1_a} \\
0 &= D_iK - D_mK^m_i + 8\pi j_i,\label{eq:3p1_b} \\
\partial_t K_{ij} &= \beta^m\partial_mK_{ij} + K_{mj}\partial_i\beta^m + K_{im}\partial_j\beta^m - D_iD_j\alpha \label{eq:3p1_c}\\ 
&+ \alpha(R_{ij}+KK_{ij}-2K_{im}K^m_{j})+4\pi\alpha\left[(S-\rho)\gamma_{ij}-2S_{ij}\right]\notag,
\end{align}
%% \end{subequation}
%c%
where $K_{ij} = \beta^m\partial_m\gamma_{ij} + \gamma_{mj}\partial_{i}\beta^{m} + \gamma_{im}\partial_j\beta^{m}-\partial_{t}\gamma_{ij}$, is called the extrinsic curvature and it measures
the rate at which the hypersurface deforms as it is carried forward along a normal (\cite{baumgarte2010numerical}). We also introduced the projections of the stress tensor: $\rho = T_{\mu\nu} n^{\mu} n^{\nu}$, $j_{\alpha}= -\perp^{\nu}_{\alpha} T_{\mu\nu} n^{\nu}$, $S_{\alpha\beta} = \perp^{\mu}_{\alpha} \perp^{\nu}_{\beta} T_{\mu\nu}$ and $S=\gamma^{\mu\nu} S_{\mu\nu}$, while $R_{ij}$ and $R$ denote the Ricci tensor and scalar associated with $\gamma_{ij}$.

The 3+1 equations are a set of 10 equations. Equation~\ref{eq:3p1_a} is known as the Hamiltonian constraint equation. Equation~\ref{eq:3p1_b} is called the momentum constraint equation and is composed of three equations. In total, these four elliptic constraint equations play a similar role as the equations $\nabla \cdot \vec E = 4\pi\rho$ and $\nabla \cdot \vec B = 0$ which constrain the initial $\vec E$ and $\vec B$ fields in Maxwell's equations. The constraint equations must be solved prior to evolving the initial data and are usually called the \textbf{initial data equations}. The last set of six equations, Eqn.~\ref{eq:3p1_c}, are the evolution equations. As they stand, the 3+1 equations still need to be manipulated a bit in order to discretize and solve them on a computer. For the set of evolution equations, the most used schemes are BSSN (\cite{baumgarte1998numerical,shibata1995evolution}), Z4 (\cite{bona2003general}) and the Generalized Harmonic Decomposition (\cite{pretorius2005numerical}; technically, the Generalized Harmonic decomposition doesn't start from the ADM equations, see Chapter 3 for more details) which each manipulate the evolution equations into a slightly different well-posed hyperbolic system. For the initial data equations, the most used schemes are conformal tranverse traceless (CTT; \cite{bowen1980time}), conformal-thin sandwich (CTS; \cite{york1999conformal}) and the extended-conformal thin-sandwich (XCTS; \cite{pfeiffer-york:2005}) frameworks.

Alongside the field-equations, the matter equations must be solved. These come from the local conservation equations $\nabla_{\mu}T^{\mu\nu} = 0$ (this changes for the case of radiation-hydrodynamics, see Chapter 3). For Neutron-star matter, a perfect-fluid tensor and an irrotational velocity distribution are usually assumed and are coupled with some choice of equation of state (EOS). For black-holes, we set $\rho = j_{\alpha} = S_{\alpha\beta} = 0$ because there is only vacuum space. On top of the matter-equations, the equations of neutrino transport must be solved, we will look at this in detail in Chapter 3.

To extract the gravitational waveform, the Weyl scalar $\psi_{4}$, which represents the outgoing transverse radiation, is extracted at a large radius away from the simulated binary system (the ``wave-zone''). The energy, linear momentum, and angular momentum of the gravitational wave are computed by integrating the $\psi_{4}$ scalar in time (\cite{kyutoku2015dynamical}).

For a more in-depth review, see (\cite{sperhake2014numerical}), (\cite{faber2012binary}) and (\cite{shibata2011coalescence}) for BBH, NSNS and NSBH systems respectively. In the next section we discuss problems that are currently plaguing solvers for the initial data equations and then in the subsequent section we discuss new numerical methods that we plan to use to fix these problems.

\section{Current problems with Einstein Initial Data solvers}

To solve the hydrodynamics equations $\nabla_\mu T_{\mu\nu} = 0$ for a binary neutron star simulation, we require an equation of state (EOS). In its most general form the expression “equation of state” is used for any relation between thermodynamic state variables. For the case of a hydrodynamics description of a neutron star fluid, a equation of state relates the pressure of the fluid P, to it's density $\rho$, electron fraction $Y_e$, and temperature T. In simulations there are two current approaches to modeling neutron stars with temperature-dependent realistic EOSs in binaries. The first is to use EOSs in tabulated form (a set of $(P,\rho,Y_e,T)$ points) and to interpolate as required during the simulation. Since this can be computationally expensive, the more common approach is to use $n$ piece-wise polytropes with a polytropic thermal correction (\cite{deaton2013black}), (\cite{kyutoku2013black}), (\cite{bauswein2014revealing}), (\cite{kyutoku2015dynamical}). The cold piece-wise polytropic part is defined as follows,

\begin{equation}
\label{eq:7}
P_{cold} = K_i\rho^{\Gamma_i},\,\,\, \epsilon_{cold} = \epsilon_i + \frac{K_{i}\rho^{\Gamma_{i}-1}}{\Gamma_{i}-1},
\end{equation}

where $P$, $\rho$, $\epsilon$ and $K$ are the pressure, rest-mass density, specific internal energy and the polytropic constant, respectively, with i denoting the $i-th$ polytropic piece. It was found that four polytropic pieces ($n=4$) will approximate most EOSs of cold neutron matter to good accuracy (\cite{read2008neutron}). To include thermal effects when using piecewise polytropes, one splits up the pressure $P = P_{cold} + P_{th}$ and internal energy $\epsilon = \epsilon_{cold}+\epsilon_{th}$ and assumes an ideal gas relationship $P_{th} = \rho \epsilon_{th}(\Gamma_{th}-1)$ where the ideal gas index $\Gamma_{th}$ is constant for all $\rho$ and $\epsilon$ and usually set to 2. (\cite{bauswein2010testing}),(\cite{takami2014constraining}).

The main issue with solving the Einstein equations and matter equations with realistic EOSs in tabulated or piecewise-analytic form are that they are not smooth due to the multiple phase transitions and the non-analytic behavior or very steep slopes at the surface of the NS. For example, if we consider the LS220 EOS \cite{lattimer1991generalized} at low temperature and electron fraction, near the NS center the EOS can be approximated by a stiff $\Gamma \approx 7/2$ polytrope and then at slightly lower densities ($\approx 10^{14} g/cm^{3}$) the EOS begins to soften with $\Gamma \approx 1/2$ and then at even lower densities, the EOS asymptotically approaches the adiabatic index of a relativistic Fermi gas, $\Gamma \approx 4/3$. In certain coordinates, these changes can happen very close to the neutron star surface and are difficult to resolve (\cite{deaton2013black}). Furthermore, initial data solves for BNS and NSBH binaries have traditionally used multi-domain spectral finite element methods such as the SpEC elliptic solver Spells (\cite{pfeiffer2003multidomain}) and LORENE (\cite{gourgoulhon2001quasiequilibrium}). Spectral methods have the nice feature of exponential convergence when the underlying problem is smooth. However, when the problem is non-smooth such as is the case when we consider tabulated EOSs or piecewise-analytic EOS fits (e.g. piecewise-polytropes), spectral methods show poor convergence due to Gibbs phenomenon. In order to retain convergence, subdomains are often inserted by hand around the non-analytic parts (\cite{deaton2013black}). 

Finally, for currently unknown reasons, the elliptic solver Spells (\cite{pfeiffer2003multidomain},\cite{foucart2008initial},\cite{henriksson2014initial}) does not converge for high compactness NS initial-data without multiple extra corrective iteration schemes and even then, it cannot converge to high accuracy data when the binary objects are very close in separation (\cite{henriksson2014initial}). This lack of convergence could be due to mathematical non-uniqueness in solutions of the XCTS formulation of the constraint equations (\cite{cordero2009improved}), but (\cite{henriksson2014initial}) hints at the possibility that the compactness can be pushed far beyond previous simulations by using refined iteration schemes. In the next section we discuss a new powerful numerical technique that might provide us with a way around these problems.

\section{New numerical methods for BNS Initial Data}

In the last section we outlined problems with current numerical techniques when handling binary neutron star initial data. In this section, we look at the current numerical techniques in detail and then describe a new method called discontinuous Galerkin that combines the best aspects of these current techniques. Discontinuous Galerkin (DG) methods will allow us to go beyond known problems with current binary neutron star initial data. To introduce DG methods, we must first look at the standard numerical techniques used today in numerical relativity. The most common methods used in Numerical Relativity to solve the evolution or initial data equations are finite difference, finite volume methods and spectral methods (\cite{baumgarte2010numerical}). We introduce all three methods by examining the following PDE:

\begin{equation}
  \label{eqn:residual}
 R(\bar u) = 0.
\end{equation}
%
Here $R$ is some partial differential operator, usually referred to as the residual, that operates on the solution $u$ which could be composed of several fields we are solving for (e.g. the four fields in the initial data equations or the 10 components of the metric). Equation~\ref{eqn:residual} represents a continuous equation which must be discretized in order to be solved on a computer. Finite difference, finite volume and spectral methods are different ways of taking continuous equations and making them discrete and therefore they are called discretization methods. Each of the different discretization methods used in numerical relativity demand in a different way, that the discrete version of Eqn.~\ref{eqn:residual} be zero. In the finite difference method we set $R(u)$ to be zero at each of the grid points and then we Taylor expand the differential operators and represent the solution as a single number at each grid point. In finite volume methods we set the integral of the residual over an element (usually called a ``cell'') of a mesh to be zero in each of the elements and we represent the solution as a single number per cell (the average of the solution over that cell). In the spectral finite element method we break up the domain into a set of elements with simple topologies and expand the solution over a set of basis functions. We demand that the residual is $L_2$-orthogonal to these basis functions. That is, on each subdomain we have
%
\begin{equation}
  \label{eqn:l2orthog}
 \int R(\bar u)\psi_j  \mathrm{d}x = 0 \quad \forall \psi_j.
\end{equation}
%

Recently, a new discretization method has become popular. Discontinuous Galerkin (DG) methods (\cite{Reed.W;Hill.T1973,hesthaven2008nodal, Cock01,cockburn1998runge,Cockburn.B1998,Cockburn.B;Karniadakis.G;Shu.C2000}) combine the power of spectral methods in smooth regions with the shock-handling features of finite volume methods in discontinuous regions. To accomplish this, DG methods represent the solution on each element as an expansion over a set of basis functions with the residual satisfying Eqn.~\ref{eqn:l2orthog}. To couple the solution between elements, DG methods use flux terms between neighboring elements which penalize deviation of the solution at the interface. These flux terms allow DG methods to borrow the discontinuity handling techniques of the finite volume method. With these features, DG methods can potentially obtain exponential convergence even when the solution is not smooth over the entire grid (see Chapter 2 for more details). On top of this, DG methods allow us to implement several nice features:

\begin{enumerate}
\item hp-adaptivity: In DG methods there are two types of refinement, you can increase the number of basis functions (p-refinement), or you can split an element of the mesh into smaller elements (h-refinement). In smooth regions, p-refinement is preferred and in non-smooth regions h-refinement is preferred. The combination of these two types of refinement (hp-refinement) can lead to rapid convergence of the solution.
\item Minimal communication: Since each element only needs the nearest-neighbour face data to compute the penalty flux terms, the amount of communication between processors is minimal.
\item Easy Boundary handling: Boundary elements can be treated just like interior elements with the boundary conditions being applied through the penalty terms in the flux. This makes algorithms like Multigrid much easier to implement, since no special treatment is required for boundary elements.
\item Easy geometry handling: Unlike finite-difference methods which require special finite difference stencils for the boundaries of curved domains, DG methods can be applied as is to any type of domain, without any significant changes.
\end{enumerate}

In the next Chapter we will outline a novel discontinuous Galerkin code we developed. We will showcase all of the features listed above by solving several problems in numerical relativity with our code.

% Finite volume methods
% Finite volume (FV) methods were developed to solve PDEs in conservative form,
% ∂tu + ∇ · F®(u)  s, for a conserved quantity u with a flux vector F®(u) and source
% s. The equations of hydrodynamics — both Newtonian and relativistic — can be
% written in this form.
% In a FV method, the simulation domain is partitioned into cells. Cartesian
% grids are the norm, with each cell a small cubical volume in the domain. On
% this grid, the solution is discretized by encoding the cell-averaged value of the
% solution u at a grid point at the cell center. The flux F® is computed consistently
% at the interface between two neighboring cells, which results in a conservative
% method by construction. To obtain schemes with high accuracy, F® is computed
% using a broad stencil, i.e. using data from several cells; this is the problem of flux
% reconstruction. In the neighborhood of shocks, the FV method is prone to spurious
% oscillations and overshoots in the solution because of Gibbs’s phenomenon.
% So-called shock-capturing schemes ensure the solution remains physical in these
% regions.
% 7
% Today, FV methods are the standard technique for solving the equations of
% relativistic hydrodynamics in GR-hydro codes. This method is favored for its
% robustness and for the shock-capturing schemes that enable handling fluid shocks
% and stellar surfaces. The FV method nevertheless has inherent limitations when
% used as a high-order method: the large stencils required for the corresponding
% differencing and shock-capturing schemes make it difficult to adapt the grid to
% the problem geometry, and can also lead to challenges in efficiently parallelizing
% the algorithm.
% Many codes also use the FV method to solve the Einstein equations; although
% these PDEs cannot be written in conservative form, they take the similar hyperbolic
% form, and so much of the same formalism applies. The shock-capturing
% properties of the FV method are not needed for the smooth spacetime variables.
% Spectral methods
% Spectral methods also divide the computational domain into elements; these elements
% are typically large regions with simple topologies, such as cubes, spherical
% shells, etc. On each of these elements, a set of N polynomial basis functions is
% introduced. The solution u is expressed as an expansion over this basis. When
% the solution is a smooth function, the error in the expansion decreases exponentially
% as the order N is increased, giving rise to the exponential convergence of
% the spectral method. However, when there is a discontinuity in the solution u,
% the nice convergence properties of the method are lost. For this reason, spectral
% methods are not commonly used in fluid dynamics, where shocks can arise.
% Spectral methods are in use today in the Simulating eXtreme Spacetimes collab8
% oration’s Spectral Einstein Code (SpEC) to produce numerous binary black hole
% merger simulations. The high accuracy of the spectral method permits long (tens
% of orbits) and efficient inspiral simulations with excellent control of the errors
% in the waveforms. When simulating binaries that contain one or two neutron
% stars, SpEC uses the spectral method to evolve the spacetime and a FV method
% to evolve the matter . This dual-grid approach allows the spacetime to be treated
% accurately and efficiently, while still correctly handling the fluid with its shocks
% and surfaces. However, there is substantial computational expense associated
% with communicating data between the spectral and FV grids, and the difficulties
% facing the FV method still apply.
% Discontinuous Galerkin methods
% Discontinuous Galerkin (DG) methods are, in an informal sense, a hybrid between
% spectral methods and FV methods. From spectral methods, DG methods
% draw the representation of the solution, on each element, as an expansion over
% a set of basis functions. From FV methods, DG methods draw the concepts
% that enable robust handling of the hydrodynamics: the use of a unique flux
% between neighboring elements to ensure conservation, and the shock-capturing
% techniques to handle discontinuities in the solution. As a result, DG methods
% combine the properties of exponential convergence in regions where the solution
% is smooth with the ability to handle shocks. In addition, they present several
% other desirable qualities:
% 1. geometric flexibility: the grid can be deformed to conform to the symmetries
% of the problem, or to the shape of an external domain boundary;
% 2. hp-adaptivity: the grid resolution can be tailored to the problem by adapt9
% ing either the local order of approximation on the element (p-refinement),
% or the size of the (and the number of) elements (h-refinement); and,
% 3. local formulation: the method only requires exchanging data with nearestneighbor
% elements, simplifying communication patterns and enabling good
% scaling on large machines.
% The development of DG methods has undergone steady progress since the
% 1980s, with early emphasis on finding a stable formulation for non-linear conservation
% laws via the development of (low-order) shock-capturing schemes.
% More recently, in the early 2000s, work on more advanced WENO-based shockcapturing
% schemes [14, 15] promises to improve the accuracy of the method in
% problems with shocks. Paralleling these developments, the use of the DG method
% has expanded, with solutions to problems in electromagnetism, acoustics, plasma
% physics, gas dynamics, and atmospheric modeling.
% The application of the DG method to problems in relativistic astrophysics is
% recent and remains, thus far, exploratory in nature.
% The first use of a DG method for the evolution of spacetime geometry was
% by Zumbusch [16], who used a variational principle to obtain a space-time
% DG method for the linearized Einstein equations in harmonic gauge. For the
% commonly used Baumgarte-Shapiro-Shibata-Nakamura (BSSN) formulation of
% the Einstein equations, Field et al. [17] and later Brown et al. [18] developed
% DG methods in spherical symmetry. More recently, Miller and Schnetter [19]
% developed a DG method for the full BSSN equations in 3D, and showed success
% in evolving test problems.
% Efforts on the hydrodynamics side began with Radice and Rezzolla [20], who
% 10
% presented a formulation of DG for the evolution of fluids in curved spacetimes
% and evolved a neutron star in spherical symmetry. In their work, the spacetime
% is treated self-consistently by satisfying a radial constraint equation. In [21],
% Zhao and Tang implemented DG with a WENO shock-capturing scheme for
% special-relativistic hydrodynamics in 1D and 2D, and showed improved accuracy
% near shocks. Bugner et al. [22] were the first to apply DG to a 3D astrophysical
% fluid problem, evolving a neutron star in the Cowling approximation (in which
% the background metric remains fixed) and comparing different WENO schemes
% for handling of the star surface.
% Prior to the work reported here, the use of a DG method to solve simultaneously
% the coupled system of spacetime geometry and general-relativistic
% hydrodynamics has not been attempted. 
