%REFERENCES used
%https://arxiv.org/pdf/1803.07965.pdf
%https://arxiv.org/pdf/1710.05832.pdf
%https://journals.aps.org/prd/pdf/10.1103/PhysRevD.95.024029 
%Appendix D in Rezolla hydrodynamics good for Tabulated Equation of State and geometrized units
%Constraints on the neutron star equation of state from AT2017gfo using radiative transfer simulations -> good for intro paragraph
% Evaluating radiation transport errors in merger simulations using a Monte-Carlo algorithm
% https://arxiv.org/abs/1805.11581 GW170817: Measurements of neutron star radii and equation of state
% wyatts paper
% https://www.fis.unipr.it/gravity/HomePages/Thesis/PhDthesis_2009_SebastianoBernuzzi.pdf
% https://arxiv.org/pdf/1804.06308.pdf

\chapter{Introduction}
\label{chap:intro}

The initial proposals for gravitational wave interferometers were
constructed in the late 1980s with the scientific goal to detect the inspiral and merger of compact-object binaries. About two decades later, the LIGO (\cite{ligo2018gwtc}), Virgo (\cite{acernese2015advanced}) and GEO600 (\cite{affeldt2014advanced}) detectors have been developed and operated as a network from the period of 2005 to 2010. No detections were made during this initial stage of sensitivity. Alongside the early-2000 interferometer development, numerical simulations of the Einstein equations were beginning to gather ground. In 2000, the first binary neutron star merger was simulated (\cite{shibata2000simulation}), five years later the first binary black hole merger was computed after years of trial and error (\cite{pretorius2005a}) and finally in 2006 the first binary neutron star - black hole simulations were performed (\cite{shibata2006merger}). A variety of numerical relativity groups started forming at this time all around the globe, the Caltech-Cornell-CITA group (SXS; black-holes.org), the Kyoto/Tokyo group (\cite{nagakura:2014hza}), the University of Illinois at Urbana-Champaign group (UIUC), to name but a few. These groups started building simulation sets to aid in the parameter estimation studies that were expected to follow from the first detections. On September 9th, 2015, in a astonishing event during a engineering run, LIGO detected the gravitational wave from two coalescing black holes (\cite{theligoscientific:2016wfe}). Since this day, there have been multiple binary black hole waveform detections (\cite{ligo2018gwtc}). More recently however, LIGO made a landmark detection, GW170817 (\cite{abbott2017gw170817}). GW170817
coincided with the detection of a gamma ray burst, GRB 170817A and a series of observations that followed across the electromagnetic spectrum codenamed atf2017gw (\cite{villar:2017wcc}). The inferred masses of the bodies and the variety of electromagnetic observations imply that the source was a neutron star binary.

With these detections and the awarding of the 2017 Nobel prize to three LIGO members, the gravitational era of astronomy was born. More detectors are expected in the future. With the upcoming earth-based detectors KAGRA (\cite{somiya2012detector}) and LIGO-India (gw-indigo.org), there will be a worldwide detector network capable of precise source localization. On top of this, there are already plans for third generation earth-based detectors such as the Einstein Telescope (\cite{einsteintelescope}) and space based detectors such as LISA (elisascience.org) which will cover an entirely different frequency band. With more and more detectors, both space-based and earth-based, we will be able to gather data from the full frequency spectrum of gravitational waves directed towards Earth.

The LIGO detection search and parameter estimator pipeline relies heavily on waveforms computed from numerical relativity. LIGO detects signals using a technique called matched-filtering, which compares instrument data against large catalogs of theoretically modelled waveform templates. These templates are created using a mix of post-Newtonian expansions, semi-analytic models tuned to numerical relativity and full numerical relativity waveforms (\cite{sachdev2019gstlal}). Furthermore, to extract the best astrophysical information from the instrument data, it is crucial to have numerical relativity waveforms. Parameter estimation in the first LIGO detection GW150914, of two coalescing black holes, used multiple semi-analytic models, tuned to numerical relativity waveforms, to determine source characteristics (\cite{abbott2016improved}). For the LIGO detection GW170817, there was both gravitational and electromagnetic emission. Post-Newtonian (PN) waveforms were used to estimate source parameters from the instrument data because in the frequency range detected the binary was well modelled by the PN expansion (\cite{abbott2017gw170817}). Even though the gravitational waveform did not capture details about the post-merger remnant, the electromagnetic emission from GW170817 provides information about this stage. Using the EM observations, fully relativistic simulations of binary neutron star mergers were used to help extract information about the remnant and constrain different aspects of the equation of state of nuclear matter (\cite{radice2017gw170817,shibata2017gw170817}). 

Even though numerical relativity has matured greatly since the major developments of the early 2000's, there is still a lot more that needs to be achieved. The biggest problems today in numerical relativity are the simulation of compact object binaries with matter and the simulation of supernovae, both requiring a great amount of microphysics, multi-scale grids, large sets of complex non-linear PDES, fast supercomputers and modern numerical techniques. With the coming of the exascale age of supercomputing there is an increasingly realistic chance of simulating these systems with all the known microphysics. This thesis aims to make progress in two areas of numerical relativity, both aiming at laying the groundwork for future BNS codes and analysis of LIGO BNS detections. First, we seek to improve the computational techniques used to solve the Einstein field equations so that more realistic microphysics may be introduced into the BNS simulations as computing power reaches exascale and beyond. To do this, we develop a new numerical scheme and code, which we test on several problems in numerical relativity, including a problem that mimicks the phase transitions discontinuities of a neutron star and the problem of two and three-black-hole initial gravitational data. This is outlined in Chapter 2. Secondly, we seek to further probe the parameter space of binary neutron star simulations with one of the most state of the art numerical relativity codes to help understand the emission properties of these LIGO sources for the next generation of detections. This is outlined in Chapter 3. Thus, this thesis is dedicated to the improving not only the current understanding of BNS mergers with the best numerical techniques of today, but paving the way for more realistic future BNS merger simulations using new exciting methods. The remaining portion of this introductory chapter will briefly describe the physics and computational techniques needed to understand the context of Chapters 2 and 3.
We begin our introduction in Chapter 1 with a broad overview of the astrophysics of binary neutron star mergers. Then in the following sections, we narrow our focus to the numerical solution of the general-relativistic equations of hydrodynamics for BNS mergers and the problems that current numerical solvers have with these equations. We end Chapter 1 by introducing a new numerical method called discontinuous Galerkin which we plan on using to improve future BNS simulations.

%% With the BNS simulations we probe the parameter space with one of the best BNS/microphysics codes available and with our new code, we lay the groundwork for future investigations of BNS simulations which will involve even more complex microphysics.

\section{Binary Neutron Stars (BNS): Einstein's Richest \mbox{Laboratory}}

%% From Oertel EOS
%% The conditions in NS mergers are quite diverse. In
%% general they depend on the masses of the merging NSs
%% and the EoS and also on the magnetic fields and NS spins.
%% Typical temperatures in the core of a postmerger remnant
%% NS are in the range from 20 to 60 MeV (Bauswein, Janka,
%% and Oechslin, 2010). These temperatures can be well
%% exceeded in the contact layers in the early stage of the
%% merger, where extremely high temperatures up to 150 MeV
%% can occur locally (Bauswein, Janka and Oechslin, 2010;
%% Rosswog, Piran and Nakar, 2013). The highest densities in
%% the hot and rotating remnant NS are typically between 2nsat
%% and 6nsat (Hotokezaka, Kiuchi et al., 2013). In case the
%% remnant collapses to a BH, similar arguments as for failed
%% SNe apply: during the collapse much higher densities and
%% correspondingly higher temperatures are reached, but are
%% probably not important dynamically.
%% The dynamic ejecta of NS mergers originate from the crust
%% and outer core of the merging NSs. Initially, this material has
%% very low Y e in the range from 0.0 to 0.2 (Rosswog, Piran and
%% Nakar, 2013; Sekiguchi et al., 2015). Depending on the
%% temperatures reached, the degeneracy of electrons is lifted
%% and Y e increases to higher values. In the subsequent evolution,
%% neutrino absorptions also influence Y e , resulting in final
%% values in the range of roughly 0.1 to 0.4 (Wanajo et al.,
%% 2014; Sekiguchi et al., 2015). See also Foucart et al. (2016)
%% for a comparison of the thermodynamic conditions for differ-
%% ent EoS. Figure 2 shows the thermodynamic conditions
%% reached in the remnant in the aftermath of a neutron star
%% merger. For the later ejecta that appear in the form of a
%% neutrino-driven wind, extremely high entropies per baryon

%% Shibata
%% As described in sections 1.4.8 and 1.5.1 (see, e.g., figure 1.23), binary neutron stars
%% are likely to be in quasi-circular orbits (with negligible eccentricity, e ≈ 0) in a late
%% inspiral phase. They adiabatically evolve due to the gravitational-radiation reaction
%% [see equation (1.93)] as far as the orbital radius, a, is much larger than the radius
%% of neutron stars, R. For the phase where a
%%  R, each neutron star in binaries
%% can be approximated by a point particle and in addition, the orbital velocity is
%% at most 20 – 30% of the speed of light. The orbital evolution and emitted gravi-
%% tational waves in such inspiral phases are accurately and analytically determined
%% in post-Newtonian frameworks [Blanchet (2014)] combining the point-particle and
%% adiabatic approximations (see appendix H). However, for R/a >
%%  ∼ 0.2 (i.e., a <
%%  ∼ 50 –
%% 75 km for typical neutron-star radii, R = 10 – 15 km), neutron stars are deformed
%% by the tidal field of their companions and hence, the point-particle approximation
%% becomes a poor approximation. Due to the tidal deformation of neutron stars,
%% the gravitational field and the orbital velocity are modified from the results by
%% the point-particle approximation. Therefore, finite-size effects have to be taken
%% into account. In addition, for a/6m ∼ <
%%  2.4 [see equation (1.93)], the ratio of the
%% Coalescence of binary compact objects
%%  449
%% gravitational-radiation reaction time scale to the orbital period is smaller than 10.
%% Here, for m = 2.8M, 6m ≈ 25 km. Thus, for a ∼ <
%%  60 km, the adiabatic approxima-
%% tion becomes a poor approximation (although it is qualitatively acceptable and does
%% not completely break down for a >
%%  ∼ 6m). For a ∼ <
%%  30 km, the gravitational-radiation
%% reaction time scale is as short as the orbital period and hence, the system starts
%% dynamical evolution.
%% The brief summary described above shows that theoretical studies of binary neu-
%% tron stars should be done keeping the following facts in mind: (i) for a <
%%  ∼ 5R(= 50 –
%% 75 km), finite-size effects have to be incorporated; (ii) for 30 km <
%%  ∼ a <
%%  ∼ 60 km, non-
%% adiabatic effects for the inspiral orbits should be incorporated, (iii) for a ∼ <
%%  30 km,
%% the merger occurs and hence a fully dynamical treatment is the unique approach
%% for this stage. The finite-size effects can be incorporated only by fully solving
%% gravitational-field equations together with hydrodynamics equations. Hence, for
%% a<
%%  ∼ 5R, a numerical computation is necessary. However, this does not always imply
%% that numerical-relativity simulations are necessary for this phase. For a relatively
%% large orbital separation, e.g., a ∼ 50 km, the adiabatic approximation may still work,
%% because the gravitational-radiation reaction time scale is still ∼ 5 times as long as
%% the orbital period. For this phase, we may approximate the binary system in a sta-
%% tionary state when observing it in a frame comoving with the orbital velocity. Thus,
%% not only numerical-relativity simulations but also constructing quasi-equilibrium
%% sequences is one of the possible approaches for studying this evolution phase. Com-
%% puting quasi-equilibrium states is also the necessary element for the studies of binary
%% mergers, because they are used as initial data of numerical-relativity simulations.


%% Use Shibata, Faber and Metzger to put this section together
%% Make outline and where to use each
%% Make diagram like shibata

In the last section we outlined the grand scheme of this thesis and the chapters to follow. Now, we will start delving deeper into the binary neutron stars. In this section, we give a high-level overview of binary neutron star systems and the computational work that has been performed to model them. 

%add disk masses and ejecta masses maybe

The first binary neutron star system discovered was PSR B1913+16 by Russell Hulse and Joseph Taylor in 1974 (\cite{hulse:1975uf}). From observations of radio-wave pulses of the stars, it was determined that the orbit of PSR B1913+16 was shrinking at a rate of 3.5 meters per year, precisely the amount predicted by the loss of energy in gravitational wave emission (\cite{1981sciam.245...74w}). For their work, Hulse and Taylor were awarded the 1993 Nobel Prize in Physics. Since then, radio telescopes have discovered roughly a dozen binary neutron star systems, all within our Galaxy (\cite{baiottireview2016}). However, the presence of extragalactic short gamma-ray bursts, believed to be powered by binary neutron star mergers, gives indirect evidence for the existence of even more neutron star binaries. Furthermore, with the first BNS detection by LIGO, codenamed GW170817, we can expect many more gravitational wave detections of BNS systems in the future. Using updated models which include the GW170817 observation, LIGO expects a detection rate of $110-3840$ $\text{Gpc}^{-3} \text{yr}^{-1}$ (\cite{ligo2018gwtc}). This detection rate coupled with a detection radius of $\sim 107$ Mpc for the LIGO-Hanford observatory  (\cite{abbott2017gw170817}) means a lower bound of $\sim 10$ BNS mergers could be seen by LIGO per year. With the upcoming LIGO A+ upgrades it is expected that by the 2026, we may be detecting one per week (LIGO Document G1601435-v3).

There are three main stages of a neutron star binary system. These stages can be distinguished using the radius $R$ of the neutron stars and their separation $a$. For $a >> R$, the binaries orbit each other with a separation that slowly decreases in a stage known as the \textbf{inspiral} (\cite{faber2012binary,baumgarte2010numerical,shibata2015numerical,rezzolla2013relativistic}). In this stage, the stars are well approximated as point particles and orbit each other with speeds not exceeding $\sim 0.2c$ (\cite{shibata2015numerical}). During the late inspiral, when the stars are orbitting each other multiple times per second ($\mathcal{O}(10) Hz$), they start being visible by the LIGO detector. As the neutron stars approach and $a\sim 5R$, they become tidally deformed. The amount of deformation is governed by the equation of state (EOS) of the nuclear matter. At this stage the stars are orbitting at an extreme rate ($\mathcal{O}(500) Hz$). As $a \sim 30km$ the stars plunge toward each other and merge into a single hypermassive neutron star, ejecting a large amount of material in the process (\cite{shibata2015numerical}). This ejecta fuses together new nuclei whose decay releases optical radiation in an event called a ``kilonova'' (\cite{metzger:16}). This stage is known as the \textbf{merger} (\cite{faber2012binary,baumgarte2010numerical,shibata2015numerical,rezzolla2013relativistic}). Whether this newly formed massive neutron star collapses down to a black-hole depends on the total mass of the system and the EOS. For most EOS, a binary of total mass close to $3M_\odot$ will collapse within a few milliseconds after merger (\cite{bauswein2013prompt}). Once the remant has settled into either a black-hole or a massive neutron star, we have reached the \textbf{ringdown} stage (\cite{faber2012binary,baumgarte2010numerical,shibata2015numerical,rezzolla2013relativistic}). The dynamics and observational signatures of the ringdown stage are dominated by the left-over accretion disk, which drives magnetic, viscous and neutrino winds and potentially provides the energy source for a collimated polar jet creating one of the most luminous events in the universe, the short gamma ray burst. Both the merger and the ringdown stages are outside the LIGO band, so these stages cannot be probed via gravitational waves until the next-generation of detectors is here (\cite{Abbott:2017dke}).
%% and as GW170817 confirmed, is also the central engine for short gamma ray bursts (sGRB).

%add timescales here
Each stage of the binary coalescence is marked by differences in the gravitational wave. The early inspiral is represented by a sinusoidal pattern as the neutron stars slowly orbit each other like point particles (\cite{bauswein2019spectral}). As the binary first enters the LIGO band in the late inspiral, the stars become tidally deformed. This tidal deformation induces a quadrupole moment which changes the shape of the waveform (\cite{hinderer2010tidal}). The magnitude of the tidal deformation is governed by the EOS, so measurement of the tidal deformability can put constraints on the EOS and such constraints were computed for GW170817 (\cite{raithel2019constraints}). As the stars plunge toward each other, the frequency grows rapidly and reaches its peak at merger, this rapid growth of the frequency is often called the ``chirp'' because it resembles the chirp sound of a sliding whistle if the frequencies were converted to sound waves. As the cores-bounce together and rotate during merger, the proto-remnant emits waves with a multiltude of frequencies with most of the emission in three major peaks (the largest being from the rotation of the proto-remnant and the other two from the fundamental frequencies of the bouncing spring-like cores) (\cite{takami:2015}). These peaks are EOS dependent and thus can lead to constraints on the EOS, but unfortunately these peaks were outside of the LIGO frequency band for GW170817 (\cite{Abbott:2017dke}). Lastly as the remnant settles, there is a rapid decay of the amplitude as energy is lost from the remnant and it ``rings down''. For GW170817, neither the ringdown nor the merger stage could provide us with constraints the EOS. The late inspiral however provided the a measure of the tidal deformability. Using this measurement, the radius of the primary neutron star if the binary had a mass-ratio $q=1$ was constrained to be $9.8 < R < 13.2$ with a maximum mass of $2.3M_\odot$ if the remnant collapsed to a black hole (\cite{raithel2019constraints}). However, some studies have argued that the late-time electromagnetic emission from GW170817 can be better explained by a long-lived neutron star remnant (\cite{yu2018long}).  Therefore, depending on the assumed fate of the binary, implications for $M_{max}$ may vary significantly. In future LIGO observation runs, post-merger gravitational waves from the remnant may provide a clear indication of the remnant’s fate and thus provide us with better constraints on $R$ and $M_{max}$.

Until GW170817 there were two big mysteries surrounding BNS. The first mystery involved the so-called rapid neutron capture (r-process) elements. It was unclear for decades how approximately half of the elements in the Milky Way galaxy heavier than iron were formed. The formation of these elements required environments where the density of free neutrons would be so high that neutron captures on nuclei proceed much faster than $\beta$ decays. This series of neutron captures was called the r-process and such elements were therefore labelled r-process elements. In 1974, Lattimer and Schramm proposed that r-process elements could be formed in the neutron-rich matter ejected from neutron star - black-hole mergers (\cite{lattimer1974black}). Some years later, Symbalisty and Schramm proposed that that a similar mechanism of mass ejection could occur from binary neutron star systems and power the r-process (\cite{symbalisty1982neutron}). It was shown in the decade following that Newtonian BNS simulations could produce ejecta from tidal disruption with the desired neutron-richness, speed and mass to potentially produce the r-process elements (\cite{davies1994merging, ruffert1996coalescing, rosswog1998mass, freiburghaus1999r}). In the years that followed fully-general relativistic simulations were performed and showed that there was another type of ejecta, matter ejected out the poles of the binary from the shocks of the cores contracting and recoiling upon impact (\cite{oechslin2006torus,hotokezaka:13,sekiguchi2015dynamical,foucart2015low}). This type of ejecta was neutron-poor, much faster and in general less massive (\cite{foucart2015low}). Further simulations have shown that the resulting accretion disk after a remnant settles can also ejecta matter via neutrino, magnetic and viscous winds with a variety of neutron-richness, masses and speeds (\cite{fernandez2013}). Alongside these simulations, work was being achieved on the theoretical side of astrophysical r-process emission models. In 1998, Li and Paczynski first proposed that the radioactive ejecta of a NS merger could power a supernova-like thermal transient, but they did not have a realistic model of the radioactive heating (\cite{li:1998bw}). In 2010, Metzger et al. first calculated the emission luminosities following using a realistic modelling of the radioactive heating of decaying r-process nuclei (\cite{2010mnras.406.2650m}). They predicted peak luminosities of $3 x 10^{41} erg s^{-1}$ for $10^{-2}M_\odot$  of ejecta expanding at $v \approx 0.1 c$ with a spectral peak at visual wavelengths. As this was roughly 1000 times more
luminous than classical novae, they named these events “kilonovae”.  The color of the kilonova distinguishes the type of ejecta involved. In particular, ejecta with $Y_e \lessapprox 0.25$, such as the shocked polar ejecta, lacks enough neutrons to create r-process elements past $A \approx 140$ and a blue-colored fast moving kilonova is produced (\cite{metzger2014}). At least all mergers should have $Y_e \lessapprox 0.2$ ejecta from tidal-tail ejecta or disk winds, this produces a red slower-moving kilonova which should be a universal feature of all mergers. Disk wind ejecta tends to be isotropic and produces kilonovae that are both blue and red in nature. For the LIGO GW170817 detection, the  electromagnetic counterpart was codenamed AT2017fgo. Over the first few days the transient colors were blue and rapidly-evolving with a spectral peak at visual wavelengths (e.g. \cite{2017apj...848l..16s,2017apj...848l..18n,,2017apj...848l..32m,cowperthwaite:2017dyu};). At later times, the colors became substantially redder and slowly evolved on timescales of several days. The total mass of the red ejecta was estimated to be $4 × 10^{-2} M$ with a somewhat lower velocity $v \approx 0.1 c$ than the blue ejecta (e.g. \cite{cowperthwaite:2017dyu,2017apj...848l..19c,2017apj...848l..18n}). The quantity of blue ejecta from AT2017fgo was estimated to be $\sim 1-2 x 10^{-2}M_\odot$
with a faster velocity of $v \approx 0.2 c$ (\cite{cowperthwaite:2017dyu,2017apj...848l..18n}), based on fitting the observed light curves to kilonova models (\cite{metzger2017}). 

%% The GRB is understood as consequence
%% of highly collimated, ultrarelativistic polar outflows or jets of
%% low-density plasma or Poynting flux, whose energy is partly
%% converted to γ-rays at distances of 1012–1013 cm, far away
%% from the compact remnant (e.g. Piran 2004). 
%% From Just paper 2015

The second mystery involves the most luminous events in the universe, the Gamma ray burst (GRB).  GRBs were first detected in the late 1960s by U.S military satellites sent into orbit to spy on the Soviet Union nuclear testing (\cite{klebesadel1973observations}). The satellites were trained to detect short bursts of gamma-rays from expected nuclear explosions. The satellites started measuring gamma rays very frequently, but this work remained classified until it was determined the bursts were of cosmological origin (\cite{klebesadel1973observations}). Very little was known about these gamma-ray bursts until the launch of the Compton Gamma Ray Observatory (CGRO) which operated between 1991 and 2000 (\cite{fishman1995gamma}). The CGRO satellite recorded over 2700 gamma ray bursts
with the Burst And Transient Source Experiment (BATSE) (\cite{fishman1989proc}).  This experiment showed that the GRBs were isotropically distributed across the sky and originating outside of our galaxy. The BATSE results also showed the existence of two distinct populations of GRBs referred to as short and long GRBs (\cite{kouveliotou1993identification}). The former category typically last for less than 2 seconds and the latter for more than 2 seconds with distribution peaks at 0.2 seconds and 20 seconds respectively. The two types of bursts clearly had different origins. The main progenitors considered were supernovae and compact-object binaries with at least one neutron star (\cite{levan2016gamma}). It was found that the long bursts happened in star-forming galaxies and could usually be associated with a type Ic core-collapse supernova, whereas the short bursts could not (\cite{hjorth2013supernova}). This meant that while supernovae were the likely progenitor for long bursts, the progenitor for short bursts must be different. The prevailing model for the short bursts was either a BNS or NSBH merger, although the latter has not yet been detected. It was only until GW170817 and the associated GRB 170817A that the BNS progenitor model for the short bursts was confirmed. About 1.7 seconds after the gravitational wave hit earth, FERMI and INTEGRAL registered a gamma ray burst which was short in duration (2.0s) but sub-luminous ($3x10^{46} ergs/s$) compared to other charted short GRBs (\cite{monitor:2017mdv,gbm:2017lvd}). The 1.7s delay was lucky because it allowed LIGO to place an upper bound on the speed of gravity, with calculations showing a relative difference between the speed of light and speed of gravity of about $\sim 7 x 10^{-16}$ (\cite{monitor:2017mdv}). While the sub-luminosity was mysterious, later analysis showed that it could be readily explained by an off-axis jet (20-40 degrees) and thus, if we had viewed GRB 170817A head-on it would have been as luminous as the other charted sGRBs.

On top of solving two mysteries, constraining the EOS and the speed of gravity, GW170817 also put constraints on the expansion rate of the universe, $H_0$ (\cite{ligo2017gravitational}). With so much science from one detection, the future appears very bright for gravitational wave astronomy and it is clear why BNS are called Einstein's Richest Laboratory (not just because of the 100 octillion U.S. dollars worth of gold produced in the ejecta!) (\cite{baiotti2016binary}). However, on the numerical side, a lot still needs to be done. Despite continuous developments, current numerical relativity codes have not yet reached the accuracy required to model the gravitational wave signal and the electronmagnetic counterparts at the level required to extract as much information as possible from future detections (see (\cite{baiotti2016binary}). High accuracy is required because small numerical errors in the initial data solves or the evolution lead to larger errors in the waveform (see e.g. \cite{tsokaros2016initialfixed}). High-accuracy is very difficult to obtain currently because of the multi-scale nature of the problem, we have to have high enough resolution to resolve the Neutron star and the MRI instability ($\sim 100-200m$ and $\sim 10cm$ respectively), but a large enough grid to extract the waveforms far away from the remnant ($1600 km$). On top of this, most codes do not take into account all of the microphysics relevant to the evolution of the post-merger remnant, including a hot nuclear-theory based equation of state, a neutrino transport scheme accounting for both neutrino-matter and neutrino-neutrino interactions and the evolution of the magnetic fields with enough resolution to resolve the growth of magneto-hydrodynamics instabilities (\cite{foucart2015low}). That being said, slowly but surely, different levels of micro-physics are being added to the codes. The first papers that studied fully general relativistic BNS simulations including the effects of neutrinos
were (\cite{neilsen2014magnetized, palenzuela2015effects}) with a simple leakage scheme and (\cite{sekiguchi2015dynamical}) with a more complex M1 neutrino transport scheme. Both the leakage scheme and M1 transport scheme are approximate methods to deal with neutrinos which are preferred because solving the 7-dimensional Boltzmann transport equation for the neutrino distribution during a BNS simulation is currently numerically intractable. For a review of leakage and the M1 transport scheme see (\cite{foucart2015post}). These BNS simulations with neutrino cooling and neutrino transport have focused mainly on equal mass systems with $M_{ns} = 1.35M_{\odot}$. Collectively these papers find that the ejected mass is only substantial  enough to explain the total mass of r-process heavy elements in our galaxy for r-process nucleo-synthesis in the case of a softer equation of state (e.g., more compact stars). The first paper on BNS mergers with neutrino interactions using the SpEC code looked at $1.2M_{\odot}$ equal mass systems and compared a simple leakage cooling neutrino scheme with the more complicated gray M1 neutrino transport scheme, finding that the more realistic transport scheme had a significant affect on the disk composition and the outflows, producing more neutron rich material that could possibly seed r-process element creation. (\cite{radice2016dynamical}) examined the effects of eccentricity and neutrino cooling on the matter outflows and remnant disk of a LS220 equal mass binary, finding that both had significant effects, with the absence of a neutrino scheme leading to matter outflows a factor of 2 off. Finally, only very recently have there been studies examining the effects on matter outflows due to mass asymmetry in the initial binaries, with both (\cite{lehner2016unequal}) and (\cite{sekiguchi2016dynamical}) finding that mass asymmetry can affect the neutron-richness and total ejecta for both soft and stiff equations of state.

In Chapter 3 of this thesis, we will be contributing to the above growing set of BNS studies, by looking at the effect of mass asymmetry and different EOSs on matter and neutrino emissions. We will be using the SpEC code by the SXS collaboration (black-holes.org) which now has a state-of-the-art neutrino transport scheme.


%% Gamma-ray bursts (GRBs) are short-lived but extremely energetic transient events
%% lasting anywhere from a few milliseconds to several minutes. During this time-span
%% however, they are so luminous that they outshine the rest of the observable universe
%% in gamma rays. GRBs were first detected serendipitously in 1967 by U.S. military
%% satellites sent into orbit to ensure that the Soviet Union was complying with a ban
%% on atmospheric testing of nuclear weapons. Nuclear explosions have a characteristic
%% gamma-ray signature and so the military satellites were designed to detect short pulses
%% of gamma-ray emission. The satellites began measuring energetic burst of gamma rays
%% with energies in the range 0.2-1.5 MeV on average once per day. Understandably, the
%% work was classified for several years until it was determined that the bursts were of
%% astronomical origin (not, as the military feared, due to Soviet forces testing nuclear
%% weapons on the far side of the moon!). The results for 16 short bursts in the previously
%% mentioned energy range showing “significant time structure” were published in the
%% public domain by Klebesadel et al. (1973).


%% For a long time it was unclear how approximately half of the elements in the Galaxy heavier than iron, Lattimer & Schramm (1974) proposed that the coalescence of a binary system consisting of a NS and
%% a stellar mass black hole (BH) would provide a promising source of neutron-rich ejecta conducive to the
%% r-process with a very low electron fraction Ye = np/(nn+np), where np and nn are the densities of protons
%% and neutrons, respectively. Following the ejection of NS matter through the outer binary Lagrange points
%% by tidal forces, its rapid decompression from nuclear densities would naturally result in the formation of
%% heavy nuclei through neutron capture (Lattimer et al., 1977; Meyer, 1989). Symbalisty & Schramm (1982)
%% and Eichler et al. (1989) proposed that a similar mechanism of mass ejection could occur from merging
%% compact binaries consisting of two NSs. The ejecta from the mergers. Roughly 60 years ago, Burbidge et al. (1957) and Cameron (1957) recognized that approximately half of the elements in the Galaxy heavier than iron must have been produced in an environment in which
%% 2

%% Debris from the merger which is not immediately unbound can possess enough angular momentum
%% to circularize into an accretion disk around the central remnant, providing an agent to power an ultra-
%% relativistic GRB jet (e.g. Narayan et al. 1992; §3). Slower expanding outflows from this remnant disk,
%% which occur on timescales of up to seconds post merger, provide another important source of r-process
%% ejecta (e.g. Metzger, Piro & Quataert 2008; Dessart et al. 2009). The quantity of mass in the disk outflows
%% Mej
%%  disk
%%  scales approximately with the original mass of the torus Mt, with Mej
%%  disk
%%  ≈ 0.2 − 0.4Mt (Fernández
%% & Metzger, 2013; Perego et al., 2014; Just et al., 2015; Fernández et al., 2015; Siegel & Metzger, 2017).
%% Because the mass of the torus increases with both the mass ratio of the binary and the lifetime of the
%% disk
%% hypermassive NS (e.g. Hotokezaka et al. 2013), Mej
%%  is also an decreasing function of q and Mrem /Mmax ,
%% i.e. an asymmetric merger or long-lived NS remnant produces a greater quantity of disk ejecta. For a
%% massive torus & 0.1 − 0.2M the disk ejecta mass Mej
%%  disk
%%  ∼ 0.05 − 0.1M can greatly exceed that of
%% the dynamical ejecta. The electron fraction distribution of the disk outflows, though generally broad
%% Ye ∼ 0.1 − 0.4 (Just et al., 2015), depends on the lifetime of the central neutron star remnant due to the
%% de-neutronizing impact of its strong electron neutrino luminosity. The average Ye of the disk outflow grows
%% with the time the hyper- or supra-massive NS survives before collapsing to a BH (Metzger & Fernández
%% 2014; Perego et al. 2014). Disk outflow simulations find that the unbound matter achieves asymptotic
%% speeds vej ≈ 0.03 − 0.1 c which are typically 2 − 3 times lower than the velocity of the dynamical ejecta.

%% Using updated models including the GW170817 observation, LIGO expects a detection rate of $110-3840 Gpc^-3 y^-1$ \cite{ligo2018gwtc} and with a Hanford detector radius of $\sim 107 Mpc$ (Livingston has $\sim 218 Mpc$ radius \cite{abbott2017gw170817} this means a minimum of $\sim 10$ BNS mergers could be detected by LIGO per year.

%% From rezzolla
%% Finally, the very strong magnetic fields (i.e., 108 –1010 G) that are expected to endow the
%% neutron stars before the merger and which will be inherited by the HMNS, can redistribute the
%% angular momentum, transporting it outwards and reducing the amount of differential rotation
%% that is essential in supporting the HMNS against gravitational collapse. The ratio between the
%% magnetic tension and the pressure gradients scales like the ratio between the magnetic pres-
%% sure and the gas pressure and this ratio increases (although remaining less than one) after the
%% merger because the magnetic fields are stronger and the HMNS is more extended and with
%% smaller pressure gradients (Giacomazzo et al., 2011). As a result, magnetic fields can “ac-
%% celerate” the collapse of the HMNS, but only if sufficiently strong for the magnetic tension
%% to be comparable to or larger than the normal pressure gradients. Hence, the efficiency in
%% angular-momentum redistribution will be proportional to the intensity of the (square of the)
%% magnetic field and thus essentially unchanged for small magnetic fields, such as B0  108 G.
%% For larger values, however, the magnetic fields will also introduce a magnetic pressure pro-
%% viding an additional pressure support and thus either compensating or even dominating the
%% angular-momentum redistribution, with an overall delay of the collapse (Giacomazzo et al.,
%% 2011). We should also remark that the HMNS could be subject to a magnetorotational insta-
%% bility (MRI), which could then increase exponentially the strength of the magnetic field (Duez
%% et al., 2006; Siegel et al., 2013).




%% Neutron stars are amongst the most compact and extreme objects known in the universe and are believed to be born from the result of
%% massive stars going supernova. With core densities exceeding far beyond that
%% of the nucleus, conditions unreachable on earth, neutron stars provide an exceptional testing ground for nuclear physics. In particular, the merger of two neutron stars provides us with an unique opportunity to study the high density region of the equation of state (EOS), an equation describing the internal properties of the star. Furthermore, as confirmed by GW170817, NS mergers are progenitors for short Gamma ray bursts (sGRBs) and the
%% heavy neutron-rich elements in the universe, whose synthesis in the fast moving neutron-star ejecta produces the optical and near-infrared EM counterparts that accompany the gravitational wave signal. 

%% We can probe the EOS via the waveform in two main ways. First, as the stars come into close contact they start  


%% It is expected that with the increasing sensitivity of gravitational wave
%% interferometers multiple detections of merging BNSs will be made in the next years (\cite{ligo2018gwtc}). Therefore it will be crucial
%% to study the properties of these fascinating systems in order to extract information
%% from the data. While an analytical approach in general relativity is possible for the stage in which the two
%% bodies are distant, numerical computation of the field equations is required
%% for the last few orbits of the inspiral, the merger and the post-merger remnant stages. Thus it is imperative to have fully generalitivistic simulations of BNS mergers and NSBH mergers in order to maximize the science potential of the next era of detections.

\section{Simulating BNS: General relativistic hydrodynamics}

In the previous section we gave a broad overview of the physics of binary neutron star systems and the computational work to simulate their merger. In this section we take a closer look at the equations involved to simulate BNS systems, namely, the Einstein field equations and the equations of relativistic hydrodynamics.

In their usual form, space and time are treated on equal footing in the Einstein equations. From the perspective of performing a numerical evolution however, we need to reformulate the problem as an initial value problem where we have a set of initial gravitational and matter data at some time $t$ and a set of evolution equations which we can use to get the updated data at a later time. To do this, we make the ansatz that space-time can be treated as a time sequence of spatial hypersurfaces. With this ansatz, the space-time metric $g_{\mu\nu}$ can be decomposed into

\begin{equation}
\label{eq:4}
ds^{2} = g_{\mu\nu}dx^{\mu}dx^{\nu} = -\alpha^2dt^2 + \gamma_{ij}(dx^i+\beta^idt)(dx^j+\beta^jdt),
\end{equation}
%
where the spatial metric $\gamma_{ij}$ is a function of the spatial coordinates $x^{i}$ and $t$, $\alpha$ is the lapse function that measures proper time between neighboring hypersurfaces along their timelike unit normals $n^{\mu}$ and $\beta^i$ is called the shift, which determines how coordinate labels move between each hypersurface. This is known as the 3+1 decomposition of the metric (\cite{arnowitt1959dynamical}).

Now we need to decompose the Einstein field equations into a set of evolution and constraint equations involving the quantities $\beta^i$, $\alpha$ and $\gamma_{ij}$. To do this, we introduce the projection operator $\perp^{\alpha}_{\beta} = \delta^{\alpha}_{\beta} + n^{\alpha} n_{\beta}$, which can be easily proven to project the space-time components orthogonal to $n^{\mu}$ out of any space-time vector.

The three possible projections of the Einstein field equations: $n^{\mu} n^{\nu} G_{\mu\nu} = 8\pi n^{\mu} n^{\nu} T_{\mu\nu}$, $n^{\mu}\perp^{\nu}_{\delta}G_{\mu\nu} = 8\pi n^{\mu} \perp^{\nu}_{\delta} T_{\mu\nu}$, $\perp^{\mu}_{\rho} \perp^{\nu}_{\delta} G_{\mu\nu} = 8\pi \perp^{\mu}_{\rho} \perp^{\nu}_{\delta} T_{\mu\nu}$ lead to the three York/ADM 3+1 equations respectively:
%
%% \begin{subequation}
\begin{align}
0 &= R + K^{2} - K^{mn}K_{mn} -16\pi\rho,\label{eq:3p1_a} \\
0 &= D_iK - D_mK^m_i + 8\pi j_i,\label{eq:3p1_b} \\
\partial_t K_{ij} &= \beta^m\partial_mK_{ij} + K_{mj}\partial_i\beta^m + K_{im}\partial_j\beta^m - D_iD_j\alpha \label{eq:3p1_c}\\ 
&+ \alpha(R_{ij}+KK_{ij}-2K_{im}K^m_{j})+4\pi\alpha\left[(S-\rho)\gamma_{ij}-2S_{ij}\right]\notag,
\end{align}
%% \end{subequation}
%c%
where $K_{ij} = \beta^m\partial_m\gamma_{ij} + \gamma_{mj}\partial_{i}\beta^{m} + \gamma_{im}\partial_j\beta^{m}-\partial_{t}\gamma_{ij}$, is called the extrinsic curvature and it measures
the rate at which the hypersurface deforms as it is carried forward along a normal (\cite{baumgarte2010numerical}). We also introduced the projections of the stress tensor: $\rho = T_{\mu\nu} n^{\mu} n^{\nu}$, $j_{\alpha}= -\perp^{\nu}_{\alpha} T_{\mu\nu} n^{\nu}$, $S_{\alpha\beta} = \perp^{\mu}_{\alpha} \perp^{\nu}_{\beta} T_{\mu\nu}$ and $S=\gamma^{\mu\nu} S_{\mu\nu}$, while $R_{ij}$ and $R$ denote the Ricci tensor and scalar associated with $\gamma_{ij}$.

The 3+1 equations are a set of 10 equations. Equation~\ref{eq:3p1_a} is known as the Hamiltonian constraint equation. Equation~\ref{eq:3p1_b} is called the momentum constraint equation and is composed of three equations. In total, these four elliptic constraint equations play a similar role as the equations $\nabla \cdot \vec E = 4\pi\rho$ and $\nabla \cdot \vec B = 0$ which constrain the initial $\vec E$ and $\vec B$ fields in Maxwell's equations. The constraint equations must be solved prior to evolving the initial data and are usually called the \textbf{initial data equations}. The last set of six equations, Eqn.~\ref{eq:3p1_c}, are the evolution equations. As they stand, the 3+1 equations are ill-posed and still need to be manipulated a bit in order to discretize and solve them on a computer. For the set of evolution equations, the most used schemes are BSSN (\cite{baumgarte1998numerical,shibata1995evolution}), Z4 (\cite{bona2003general}) and the Generalized Harmonic Decomposition (\cite{pretorius2005numerical}; technically, the Generalized Harmonic decomposition doesn't start from the ADM equations, see Chapter 3 for more details) which each manipulate the evolution equations into a slightly different well-posed hyperbolic system. For the initial data equations, the most used schemes are conformal tranverse traceless (CTT; \cite{bowen1980time}), conformal-thin sandwich (CTS; \cite{york1999conformal}) and the extended-conformal thin-sandwich (XCTS; \cite{pfeiffer-york:2005}) frameworks.

Alongside the field-equations, the matter equations must be solved. These come from the local conservation equations $\nabla_{\mu}T^{\mu\nu} = 0$ (this changes for the case of radiation-hydrodynamics, see Chapter 3). For Neutron-star matter, a perfect-fluid tensor and an irrotational velocity distribution are usually assumed and are coupled with some choice of equation of state (EOS) to complete the system(\cite{faber2012binary}). For black-holes, we set the source terms $\rho = j_{\alpha} = S_{\alpha\beta} = 0$ because there is only vacuum space. On top of the matter-equations, the equations of neutrino transport must be solved, we will look at this in detail in Chapter 3. Furthermore, if magnetic fields are included, we must also solve the equations of magnetohydronamics (\cite{baumgarte2003general,shibata2012radiation}).

To extract the gravitational waveform, the Weyl scalar $\psi_{4}$, which represents the outgoing transverse radiation, is extracted at a large radius away from the simulated binary system (the ``wave-zone''). The energy, linear momentum and angular momentum of the gravitational wave are computed by integrating the $\psi_{4}$ scalar in time (\cite{kyutoku2015dynamical}).

For a more in-depth review, see (\cite{sperhake2014numerical}), (\cite{faber2012binary}) and (\cite{shibata2011coalescence}) for BBH, NSNS and NSBH systems respectively. In the next section we discuss problems that are currently plaguing solvers for the initial data equations and then in the subsequent section we discuss new numerical methods that we plan to use to fix these problems.

\section{Simulating BNS: Current problems}

To solve the hydrodynamics equations $\nabla_\mu T_{\mu\nu} = 0$ for a binary neutron star simulation, we require an equation of state (EOS). In its most general form the term equation of state is used for any relation between thermodynamic state variables. For the case of a hydrodynamics description of a neutron star fluid, a equation of state relates the pressure of the fluid $P$, to it's density $\rho$, electron fraction $Y_e$ and temperature $T$. In simulations there are two current approaches to modeling neutron stars with temperature-dependent realistic EOSs in binaries. The first is to use EOSs in tabulated form (a set of $(P,\rho,Y_e,T)$ points) and to interpolate between tabular points as required during the simulation. Since this can be computationally expensive, more approximate approaches have been tried. The most common approximant is to use $n$ piece-wise polytropes with a polytropic thermal correction (\cite{deaton2013black,kyutoku2013black,bauswein2014revealing,kyutoku2015dynamical}). Following this approach, the cold ($T \approx 0$) piece-wise polytropic part of the EOS is defined as follows
%
\begin{equation}
\label{eq:7}
P_{cold} = K_i\rho^{\Gamma_i},\,\,\, \epsilon_{cold} = \epsilon_i + \frac{K_{i}\rho^{\Gamma_{i}-1}}{\Gamma_{i}-1},
\end{equation}
%
where $P$, $\rho$, $\epsilon$, $K$ and $\Gamma$ are the pressure, rest-mass density, specific internal energy, polytropic constant and polytropic index respectively, with i denoting the $i-th$ polytropic piece. It was found that four polytropic pieces ($n=4$) will approximate most EOSs of cold neutron matter to good accuracy (\cite{read2008neutron}). However, a piecewise-polytopic EOS is only valid for neutron stars with a temperature $T \approx 0$. In neutron star mergers, temperatures can reach up to $T \sim 50 MeV$, so a polytropic EOS would not be realistic. To include thermal effects when using piecewise polytropes, one splits up the pressure $P = P_{cold} + P_{th}$ and internal energy $\epsilon = \epsilon_{cold}+\epsilon_{th}$ and assumes an ideal gas relationship $P_{th} = \rho \epsilon_{th}(\Gamma_{th}-1)$ where the ideal gas index $\Gamma_{th}$ is constant for all $\rho$ and $\epsilon$ and usually set to 2. (\cite{bauswein2010testing,takami2014constraining}).

The main issue with solving the Einstein equations and matter equations with realistic EOSs in tabulated or with an approximate piecewise-analytic form is that the EOS are not smooth due to the multiple phase transitions and the non-analytic behavior or very steep slopes at the surface of the NS. For example, let's consider the LS220 EOS (a commonly used phenomenological nuclear matter EOS for astrophysical application, see \cite{lattimer1991generalized}) at low temperature and electron fraction. Near the NS center the EOS can be approximated by a stiff $\Gamma \approx 7/2$ polytrope and then at slightly lower densities ($\approx 10^{14} g/cm^{3}$) the EOS begins to soften with $\Gamma \approx 1/2$ and then at even lower densities, the EOS asymptotically approaches the adiabatic index of a relativistic Fermi gas, $\Gamma \approx 4/3$. In certain coordinates, these changes can happen very close to the neutron star surface and are difficult to resolve (\cite{deaton2013black}). Furthermore, initial data solves for BNS and NSBH binaries have traditionally used multi-domain spectral finite element methods such as the SpEC elliptic solver Spells (\cite{pfeiffer2003multidomain}) and LORENE (\cite{gourgoulhon2001quasiequilibrium}). Spectral methods have the nice feature of exponential convergence when the underlying problem is smooth. However, when the problem is non-smooth such as is the case when we consider tabulated EOSs or piecewise-analytic EOS fits (e.g. piecewise-polytropes), spectral methods show poor convergence. In order to retain convergence, subdomains are often inserted by hand around the non-analytic parts (\cite{deaton2013black}). 
%
Finally, for currently unknown reasons, the elliptic solver Spells (\cite{pfeiffer2003multidomain},\cite{foucart2008initial},\cite{henriksson2014initial}) used by the SXS collaboration (black-holes.org) does not converge for high compactness NS initial-data without multiple extra corrective iteration schemes and even then, it cannot converge to high accuracy data when the binary objects are very close in separation (\cite{henriksson2014initial}). This lack of convergence could be due to mathematical non-uniqueness in solutions of the XCTS formulation of the Einstein constraint equations (\cite{cordero2009improved}), but (\cite{henriksson2014initial}) hints at the possibility that the compactness can be pushed far beyond previous simulations by using refined iteration schemes. In the next section we discuss a new powerful numerical technique that might provide us with a way around these problems.

\section{Simulating BNS: New numerical methods}

In the last section we outlined problems with current numerical solution techniques when handling binary neutron star initial data. In this section, we look at the current numerical techniques in detail and then describe a new method called discontinuous Galerkin that combines the best aspects of these current techniques. Discontinuous Galerkin (DG) methods will allow us to go beyond known problems with current binary neutron star initial data.
To introduce DG methods, we must first look at the standard numerical techniques used today in numerical relativity. The most common methods used in Numerical Relativity to solve the evolution or initial data equations are finite difference, finite volume methods and spectral methods (\cite{baumgarte2010numerical}). We introduce all three methods by examining the following PDE:
%
\begin{equation}
  \label{eqn:residual}
 R(\bar u) = 0.
\end{equation}
%
Here $R$ is some partial differential operator, usually referred to as the residual, that operates on the solution $u$ which could be composed of several fields we are solving for (e.g. the four fields in the initial data equations or the 10 components of the metric). Equation~\ref{eqn:residual} represents a continuous equation which must be discretized in order to be solved on a computer. Finite difference, finite volume and spectral methods are different ways of taking continuous equations and making them discrete and therefore they are called discretization methods. Each of the different discretization methods used in numerical relativity demand in a different way, that the discrete version of Eqn.~\ref{eqn:residual} be zero. In the finite difference method we set $R(u)$ to be zero at each of the grid points and then we Taylor expand the differential operators and represent the solution as a single number at each grid point. In finite volume methods we set the integral of the residual over an element (usually called a ``cell'') of a mesh to be zero in each of the elements and we represent the solution as a single number per cell (the average of the solution over that cell). In the spectral finite element method we break up the domain into a set of elements with simple topologies and expand the solution over a set of basis functions. We demand that the $L_2$-inner product between the residual and each of these basis functions is zero. That is, on each subdomain we have
%
\begin{equation}
  \label{eqn:l2orthog}
 \int R(\bar u)\psi_j  \mathrm{d}x = 0 \quad \forall \psi_j.
\end{equation}
%

Recently, a new discretization method has become popular. Discontinuous Galerkin (DG) methods (\cite{Reed.W;Hill.T1973,hesthaven2008nodal, Cock01,cockburn1998runge,Cockburn.B1998,Cockburn.B;Karniadakis.G;Shu.C2000}) combine the power of spectral methods in smooth regions with the shock-handling features of finite volume methods in discontinuous regions. To accomplish this, DG methods represent the solution on each element as an expansion over a set of basis functions with the residual satisfying Eqn.~\ref{eqn:l2orthog}. To couple the solution between elements, DG methods use flux terms between neighboring elements which penalize deviation of the solution at the interface. These flux terms allow DG methods to borrow the discontinuity handling techniques of the finite volume method. With these features, DG methods can potentially obtain exponential convergence even when the solution is not smooth over the entire grid (see Chapter 2 for more details). On top of this, DG methods allow us to implement several nice features:

\begin{enumerate}
\item hp-adaptivity: In DG methods there are two types of refinement, you can increase the number of basis functions (p-refinement), or you can split an element of the mesh into smaller elements (h-refinement). In smooth regions, p-refinement is preferred and in non-smooth regions h-refinement is preferred. The combination of these two types of refinement (hp-refinement) can lead to rapid convergence of the solution.
\item Minimal communication: Since each element only needs the nearest-neighbour face data to compute the penalty flux terms, the amount of communication between processors is minimal.
\item Easy Boundary handling: Boundary elements can be treated just like interior elements with the boundary conditions being applied through the penalty terms in the flux. This makes algorithms like Multigrid much easier to implement, since no special treatment is required for boundary elements.
\item Easy geometry handling: Unlike finite-difference methods which require special finite difference stencils for the boundaries of curved domains, DG methods can be applied as is to any type of domain, without any significant changes.
\end{enumerate}

In the next Chapter we will outline a novel discontinuous Galerkin code we developed. We will showcase all of the features listed above by solving several problems in numerical relativity with our code. The future goal of this code will be to solve for BNS initial data with realistic EOS, spins and mass-ratios to high accuracy.

% Finite volume methods
% Finite volume (FV) methods were developed to solve PDEs in conservative form,
% ∂tu + ∇ · F®(u)  s, for a conserved quantity u with a flux vector F®(u) and source
% s. The equations of hydrodynamics — both Newtonian and relativistic — can be
% written in this form.
% In a FV method, the simulation domain is partitioned into cells. Cartesian
% grids are the norm, with each cell a small cubical volume in the domain. On
% this grid, the solution is discretized by encoding the cell-averaged value of the
% solution u at a grid point at the cell center. The flux F® is computed consistently
% at the interface between two neighboring cells, which results in a conservative
% method by construction. To obtain schemes with high accuracy, F® is computed
% using a broad stencil, i.e. using data from several cells; this is the problem of flux
% reconstruction. In the neighborhood of shocks, the FV method is prone to spurious
% oscillations and overshoots in the solution because of Gibbs’s phenomenon.
% So-called shock-capturing schemes ensure the solution remains physical in these
% regions.
% 7
% Today, FV methods are the standard technique for solving the equations of
% relativistic hydrodynamics in GR-hydro codes. This method is favored for its
% robustness and for the shock-capturing schemes that enable handling fluid shocks
% and stellar surfaces. The FV method nevertheless has inherent limitations when
% used as a high-order method: the large stencils required for the corresponding
% differencing and shock-capturing schemes make it difficult to adapt the grid to
% the problem geometry and can also lead to challenges in efficiently parallelizing
% the algorithm.
% Many codes also use the FV method to solve the Einstein equations; although
% these PDEs cannot be written in conservative form, they take the similar hyperbolic
% form and so much of the same formalism applies. The shock-capturing
% properties of the FV method are not needed for the smooth spacetime variables.
% Spectral methods
% Spectral methods also divide the computational domain into elements; these elements
% are typically large regions with simple topologies, such as cubes, spherical
% shells, etc. On each of these elements, a set of N polynomial basis functions is
% introduced. The solution u is expressed as an expansion over this basis. When
% the solution is a smooth function, the error in the expansion decreases exponentially
% as the order N is increased, giving rise to the exponential convergence of
% the spectral method. However, when there is a discontinuity in the solution u,
% the nice convergence properties of the method are lost. For this reason, spectral
% methods are not commonly used in fluid dynamics, where shocks can arise.
% Spectral methods are in use today in the Simulating eXtreme Spacetimes collab8
% oration’s Spectral Einstein Code (SpEC) to produce numerous binary black hole
% merger simulations. The high accuracy of the spectral method permits long (tens
% of orbits) and efficient inspiral simulations with excellent control of the errors
% in the waveforms. When simulating binaries that contain one or two neutron
% stars, SpEC uses the spectral method to evolve the spacetime and a FV method
% to evolve the matter . This dual-grid approach allows the spacetime to be treated
% accurately and efficiently, while still correctly handling the fluid with its shocks
% and surfaces. However, there is substantial computational expense associated
% with communicating data between the spectral and FV grids and the difficulties
% facing the FV method still apply.
% Discontinuous Galerkin methods
% Discontinuous Galerkin (DG) methods are, in an informal sense, a hybrid between
% spectral methods and FV methods. From spectral methods, DG methods
% draw the representation of the solution, on each element, as an expansion over
% a set of basis functions. From FV methods, DG methods draw the concepts
% that enable robust handling of the hydrodynamics: the use of a unique flux
% between neighboring elements to ensure conservation and the shock-capturing
% techniques to handle discontinuities in the solution. As a result, DG methods
% combine the properties of exponential convergence in regions where the solution
% is smooth with the ability to handle shocks. In addition, they present several
% other desirable qualities:
% 1. geometric flexibility: the grid can be deformed to conform to the symmetries
% of the problem, or to the shape of an external domain boundary;
% 2. hp-adaptivity: the grid resolution can be tailored to the problem by adapt9
% ing either the local order of approximation on the element (p-refinement),
% or the size of the (and the number of) elements (h-refinement); and,
% 3. local formulation: the method only requires exchanging data with nearestneighbor
% elements, simplifying communication patterns and enabling good
% scaling on large machines.
% The development of DG methods has undergone steady progress since the
% 1980s, with early emphasis on finding a stable formulation for non-linear conservation
% laws via the development of (low-order) shock-capturing schemes.
% More recently, in the early 2000s, work on more advanced WENO-based shockcapturing
% schemes [14, 15] promises to improve the accuracy of the method in
% problems with shocks. Paralleling these developments, the use of the DG method
% has expanded, with solutions to problems in electromagnetism, acoustics, plasma
% physics, gas dynamics and atmospheric modeling.
% The application of the DG method to problems in relativistic astrophysics is
% recent and remains, thus far, exploratory in nature.
% The first use of a DG method for the evolution of spacetime geometry was
% by Zumbusch [16], who used a variational principle to obtain a space-time
% DG method for the linearized Einstein equations in harmonic gauge. For the
% commonly used Baumgarte-Shapiro-Shibata-Nakamura (BSSN) formulation of
% the Einstein equations, Field et al. [17] and later Brown et al. [18] developed
% DG methods in spherical symmetry. More recently, Miller and Schnetter [19]
% developed a DG method for the full BSSN equations in 3D and showed success
% in evolving test problems.
% Efforts on the hydrodynamics side began with Radice and Rezzolla [20], who
% 10
% presented a formulation of DG for the evolution of fluids in curved spacetimes
% and evolved a neutron star in spherical symmetry. In their work, the spacetime
% is treated self-consistently by satisfying a radial constraint equation. In [21],
% Zhao and Tang implemented DG with a WENO shock-capturing scheme for
% special-relativistic hydrodynamics in 1D and 2D and showed improved accuracy
% near shocks. Bugner et al. [22] were the first to apply DG to a 3D astrophysical
% fluid problem, evolving a neutron star in the Cowling approximation (in which
% the background metric remains fixed) and comparing different WENO schemes
% for handling of the star surface.
% Prior to the work reported here, the use of a DG method to solve simultaneously
% the coupled system of spacetime geometry and general-relativistic
% hydrodynamics has not been attempted. 
